# -*- coding: utf-8 -*-
#
# created by HÃ©lion du Mas des Bourboux
# < helion.du-mas-des-bourboux@cea.fr >



import subprocess
import sys
import os

import numpy
import astropy.io.fits as pyfits
from iminuit import Minuit
import matplotlib.pyplot as plt
import re
#import array
#import matplotlib.patches as mpatches
#import decimal
#import profile
import warnings
warnings.filterwarnings("error")

### My tools
import myTools
from myTools import Get_TProfile
### The Constants
from delta_const import *

### "HOME" or "ICLUST"
location__ = 'ICLUST'
### "DR12" or 'Guy' or 'Margala' or "MOCK" or 'eBOSS'
pipeline__ = 'DR12'
### False or True
reObs__ = False
### What type of FITS file will we use: 'spPlate' or 'spec'
dataFitsType__ = 'spec'


def make_all_Fits(iStart=0,iEnd=-1):

	tmp_string = "\n   ---- Starting ---- \n\n  iStart = " + str(iStart) + "  iEnd = " + str(iEnd) + "\n"

	tmp_command = "echo \"" + tmp_string + "\""
	subprocess.call(tmp_command, shell=True)

	### Path to the folder where all spectra are
	pathToSpec = Get_Path_To_Fits()
	
	### Get the catalogue
	data, plate_list = Get_Catalogue()

	sizeMax = len(data)
	if (iEnd!=-1):
		if (iEnd>sizeMax):
			iEnd=sizeMax
		if (iStart>sizeMax):
			print '  iStart>sizeMax'
			return
		iEnd += 1
		data = data[iStart:iEnd]
	
	sizeMax = len(data)

	tmp_command = "echo \"" + "  Final length = "+ str(sizeMax) + "\""
	subprocess.call(tmp_command, shell=True)

	tmp_command = "echo  \"" + "\n  Creating the FITS file" + "\""
	subprocess.call(tmp_command, shell=True)

	### Create a FITS file with only the usefull data
	plate                = pyfits.Column(name='PLATE',           format='J', array=data[:,0] )
	mjd                  = pyfits.Column(name='MJD',             format='J', array=data[:,1] )
	fiber                = pyfits.Column(name='FIBERID',         format='J', array=data[:,2] )
	
	ra                   = pyfits.Column(name='RA',              format='D',    unit='deg', array=data[:,3] )
	de                   = pyfits.Column(name='DEC',             format='D',    unit='deg', array=data[:,4] )
	zz                   = pyfits.Column(name='Z_VI',            format='D', array=data[:,5] )
	nb                   = pyfits.Column(name='NB_PIXEL',        format='I', array=numpy.zeros(sizeMax) )
	
	tmp_nbBinForest     = str(nbBinRFMax__)+'D'
	lambdaForest        = pyfits.Column(name='LAMBDA_OBS',       format=tmp_nbBinForest, unit='angstrom', array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	lambdaRFForest      = pyfits.Column(name='LAMBDA_RF',        format=tmp_nbBinForest, unit='angstrom', array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	normFluxForest      = pyfits.Column(name='NORM_FLUX',        format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	normFluxIvarForest  = pyfits.Column(name='NORM_FLUX_IVAR',   format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	deltaForest         = pyfits.Column(name='DELTA',            format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	deltaIvarForest     = pyfits.Column(name='DELTA_IVAR',       format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	
	del data
	
	ar_normFactor = []
	len_forest    = []
	
	tbhdu = pyfits.BinTableHDU.from_columns([plate, mjd, fiber, ra, de, zz, nb, lambdaForest, lambdaRFForest, normFluxForest, normFluxIvarForest, deltaForest, deltaIvarForest])
	cat_tbhdu = tbhdu.data
	
	tmp_command = "echo  \"" + "\n  Starting the loop\n\n" + "\""
	subprocess.call(tmp_command, shell=True)
	
	if (dataFitsType__=='spec'):

		### Read and write in the FITS file
		for el in cat_tbhdu:
	
			try:
				#cat = pyfits.open(pathToSpec + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits", memmap=True)[1].data
				cat = pyfits.open(pathToSpec + str(el['PLATE']) + "/spec-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits", memmap=True)[1].data
				### For DR12 Margala
				#cat = pyfits.open(pathToSpec + str(el['PLATE']) + "/corrected-spec-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits", memmap=True)[1].data
				### For mocks
				#cat = pyfits.open(pathToSpec + str(el['PLATE']) + "/mock-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits", memmap=True)[1].data
			except Exception,error:
				#tmp_string = pathToSpec + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits"
				tmp_string = pathToSpec + str(el['PLATE']) + "/spec-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits"
				#tmp_string = pathToSpec + str(el['PLATE']) + "/corrected-spec-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits"
				#tmp_string = pathToSpec + str(el['PLATE']) + "/mock-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits"
	
				tmp_command = "echo  \"" + "  File not found \n " + tmp_string + "\""
				subprocess.call(tmp_command, shell=True)
				tmp_command = "echo  \"  " + str(error)  + "\n\""
				subprocess.call(tmp_command, shell=True)
	
				ar_normFactor += [-1.]
				len_forest    += [-1.]
				continue
				
			### Apply cuts for bad pixels
			############################## 
			
			### CCD and too many sky lines
			cat = cat[ (numpy.logical_and( (cat["LOGLAM"]>=log10lambdaObsMin__) , (cat["LOGLAM"]<log10lambdaObsMax__) )) ]
			### Sky Lines
			for lines in skyLines__:
				cat = cat[ (numpy.logical_or( (cat["LOGLAM"]<=lines[0]) , (cat["LOGLAM"]>=lines[1]) )) ]
			cat = cat[ numpy.logical_and( numpy.logical_and( (cat["IVAR"]>0.), (cat["AND_MASK"]<bit16__)), (numpy.isfinite(cat["FLUX"])) ) ]
		
			### Get where to cut for lambda_RF_Norma
			tmp_logZ = numpy.log10(1.+el['Z_VI'])
			
			### Get the normalisation factor
			try:
				normFactor = numpy.mean( cat["FLUX"][ numpy.logical_and( (cat["LOGLAM"]>log10lambdaRFNormaMin__+tmp_logZ), (cat["LOGLAM"]<log10lambdaRFNormaMax__+tmp_logZ) ) ] )
			except Exception,error:
				tmp_command = "echo  \"" + "  Error in: 'normFactor = numpy.mean',  z = " + str(el['Z_VI']) + ", idx = " + str(len(ar_normFactor)+iStart) + "\""
				subprocess.call(tmp_command, shell=True)
				tmp_command = "echo  \"  " + str(error)  + "\n\""
				subprocess.call(tmp_command, shell=True)
				ar_normFactor += [-1.]
				len_forest    += [-1.]
				continue
	
			ar_normFactor += [normFactor]
		
			### Apply cuts to keep only the forest
			cat = cat[ numpy.logical_and( (cat["LOGLAM"]>=log10lambdaRFTemplateMin__+tmp_logZ) , (cat["LOGLAM"]<log10lambdaRFTemplateMax__+tmp_logZ) ) ]
			
			### Find the number of pixels
			tmp_lenCat = len(cat)
			el['NB_PIXEL'] = tmp_lenCat
			
			### Store the data
			el['NORM_FLUX'][:tmp_lenCat]      = cat["FLUX"]/normFactor
			el['NORM_FLUX_IVAR'][:tmp_lenCat] = cat["IVAR"]*normFactor*normFactor
			el['LAMBDA_OBS'][:tmp_lenCat]     = numpy.power(10., cat["LOGLAM"])
			el['LAMBDA_RF'][:tmp_lenCat]      = el['LAMBDA_OBS'][:tmp_lenCat]/(1.+el['Z_VI'])
	
			len_forest += [ len( el['LAMBDA_RF'][numpy.logical_and( (el['LAMBDA_RF']>=lambdaRFMin__) , (el['LAMBDA_RF']<lambdaRFMax__) )]) ]				
	
	print "\n  Number of forest             : " + str(len(cat_tbhdu))
	
	ar_normFactor = numpy.asarray(ar_normFactor)
	len_forest = numpy.asarray(len_forest)

	print len(cat_tbhdu)
	print len((ar_normFactor>0.))
	print len(numpy.isfinite(ar_normFactor))
	print len((len_forest>=nbBinRFMin__))

	cat_tbhdu = cat_tbhdu[ numpy.logical_and( numpy.logical_and((ar_normFactor>0.),(numpy.isfinite(ar_normFactor))), (len_forest>=nbBinRFMin__)) ]
	print '  ', len(cat_tbhdu)
	cat_tbhdu = cat_tbhdu[ (cat_tbhdu['NB_PIXEL'] >= nbBinRFMin__) ]
	print '  ', len(cat_tbhdu)
	print   "  Number of forest after cut   : " + str(len(cat_tbhdu))
	
	tbhdu = pyfits.BinTableHDU(data=cat_tbhdu)
	tbhdu.update()

	path = Get_Path_To_Save_New_Fits(iStart,iEnd)
	#tbhdu.writeto(path, clobber=True)

	print "\n\n\n"
	
def Merge_Files():
	
	where = Get_Data_Fits_File()
	folder = where[0]
	path   = where[1]
	path   = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/DR12_reObs/DR12_reObs.fits'
	folder = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/DR12_reObs/'
	if (pipeline__=="DR12" or pipeline__=='Guy' or pipeline__=='Margala'):
		if (reObs__):
			scheme = 'DR12_reObs_'
		else:
			scheme = 'allDR12_test_'
	elif (pipeline__=='MOCK'):
		scheme = "Mock__DR11_"
	lenScheme = len(scheme)
	
	### Get the list of files
	all_t = os.listdir(folder)	
	tmp_all_t = []
	for el in all_t:
                if (el[:lenScheme]==scheme):
                        tmp_all_t.append(el)
	all_t = tmp_all_t

	### Sort the list of files
	convert      = lambda text: int(text) if text.isdigit() else text
	alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]
	all_t = sorted(all_t, key = alphanum_key)

	### Get the FitsFile
	all_t_file  = []
	for el in all_t:
		all_t_file.append( pyfits.open(folder+el,  memmap=True) )
		print folder+el
	
	### Get arrays of size of FitsFile
	all_t_nrows = []
	for el in all_t_file:
		all_t_nrows.append( el[1].data.shape[0] )
	nrowsTot = numpy.sum(all_t_nrows)

	print 
	print '  ', len(all_t_nrows)
	print '  ', nrowsTot

	### Set the Fits_File which will contain all
	hdu = pyfits.BinTableHDU.from_columns(all_t_file[0][1].columns, nrows=nrowsTot)

	### Set the values of each rows
	first = 0
	last  = all_t_nrows[0]
	for i in range(1, len(all_t_nrows)):
		first += all_t_nrows[i-1]
		last  += all_t_nrows[i]
		print first, last
		for colname in all_t_file[0][1].columns.names:
			hdu.data[colname][first:last] = all_t_file[i][1].data[colname]
	
	## Map
	plt.plot(hdu.data["RA"], hdu.data["DEC"], linestyle="", marker="o")
	plt.show()

	hdu.writeto(path, clobber=True)

	return
def Get_Template():
	'''
	'''
	
	nbLoop = 10
	
	### Values
	init_eta = 1.
	init_sigma2LSS = 0.1
	
	### Init the template and corrections
	eta               = [init_eta]
	sigma2LSS         = [init_sigma2LSS]

	tmp_range  = [lambdaRFMin__] #numpy.arange(lambdaRFTemplateMin__-1.,lambdaRFTemplateMax__+1.,(2.+lambdaRFTemplateMax__-lambdaRFTemplateMin__)/nbBinRFTemplate__ )
	tmp_range2 = [lambdaObsMin__] #numpy.arange(lambdaObsMin__-1.,lambdaObsMax__+1.,(2.+lambdaObsMax__-lambdaObsMin__)/nbBinObs__ )
	tmp_range3 = numpy.arange(-3.,6.,9./40 )

	template          = [ (tmp_range,  numpy.ones(len(tmp_range)),   numpy.ones(len(tmp_range))) ]
	residualRF        = [ (tmp_range,  numpy.zeros(len(tmp_range)),  numpy.ones(len(tmp_range))) ]
	residualObs       = [ (tmp_range2, numpy.zeros(len(tmp_range2)), numpy.ones(len(tmp_range2))) ]
	meanTransRF       = [ (tmp_range,  numpy.ones(len(tmp_range)),   numpy.ones(len(tmp_range))) ]
	meanTrandObs      = [ (tmp_range2, numpy.ones(len(tmp_range2)),  numpy.ones(len(tmp_range2))) ]
	templateCorrected = [ (tmp_range,  numpy.ones(len(tmp_range)),   numpy.ones(len(tmp_range))) ]
	varPipeline       = [ (tmp_range3, numpy.power(sigma2LSS[0]+1./(eta[0]*numpy.power(10,tmp_range3)),-1.), numpy.zeros(len(tmp_range3))) ]
	
	### Get Data
	####################################################################
	### ,mode='update' ##, memmap=True
	where = Get_Data_Fits_File()
	path  = where[1]
	path = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/allDR12.fits'
	print path
	file_cat = pyfits.open(path)
	print len(file_cat[1].data)
	cat = file_cat[1].data
	print len(cat)
	print numpy.max(cat['NB_PIXEL'])
	
	for loopIdx in numpy.arange(0,nbLoop):
	
		tmp_command = "echo  \"  " +  "  ---- " + str(loopIdx) + " ---- " + "\n\""
		subprocess.call(tmp_command, shell=True)

		### Find delta of catalogue
		for el in cat:

			### If doning the second time
			### else do:
			#if (loopIdx==0):
			#	ar_cut     = (el['NORM_FLUX_IVAR']>minDeltaIvar__)
			#else:
			ar_cut     = (el['DELTA_IVAR']>minDeltaIvar__)
			
			tmp_interp = numpy.interp(el['LAMBDA_RF'][ar_cut], template[loopIdx][0], template[loopIdx][1])
			#if (loopIdx==0):
			#	ar_weight  = numpy.power(el['LAMBDA_OBS'][ar_cut]/(lambdaRFLya__*onePlusZ0__), halfGama__)/(sigma2LSS[loopIdx]+1./(eta[loopIdx]*el['NORM_FLUX_IVAR'][ar_cut]))
			#else:
			ar_weight  = numpy.power(el['LAMBDA_OBS'][ar_cut]/(lambdaRFLya__*onePlusZ0__), halfGama__)/(sigma2LSS[loopIdx]+1./(eta[loopIdx]*el['DELTA_IVAR'][ar_cut]))

			### Set minuit
			#tmp_lambdaRF = el['LAMBDA_RF'][ar_cut]-numpy.mean(el['LAMBDA_RF'][ar_cut])
			def chi2(alpha,beta):
				return numpy.sum(numpy.power((el['NORM_FLUX'][ar_cut]-(alpha+beta*el['LAMBDA_RF'][ar_cut])*tmp_interp),2.)*ar_weight)

			m = Minuit(chi2, alpha=1.,error_alpha=1., beta=0.,error_beta=1.,print_level=-1, pedantic=False)
			m.migrad()

			tmp_interp *= (m.values['alpha']+m.values['beta']*el['LAMBDA_RF'][ar_cut])*numpy.interp(el['LAMBDA_OBS'][ar_cut], meanTrandObs[loopIdx][0], meanTrandObs[loopIdx][1])*numpy.interp(el['LAMBDA_RF'][ar_cut], meanTransRF[loopIdx][0], meanTransRF[loopIdx][1])

			tmp_lenCat = len(el['LAMBDA_RF'][ar_cut])
			el['DELTA'][:tmp_lenCat]        = el['NORM_FLUX'][ar_cut]/tmp_interp-1.
			el['DELTA_IVAR'][:tmp_lenCat]   = el['NORM_FLUX_IVAR'][ar_cut]*tmp_interp*tmp_interp
			el['NB_PIXEL'] = tmp_lenCat


		### Set arrays
		################################################################
		ar_cut          = (cat['DELTA_IVAR']>minDeltaIvar__)
		ar_flux         = cat['NORM_FLUX'][ ar_cut ]
		ar_lambdaRF     = cat['LAMBDA_RF'][ ar_cut ]
		ar_lambdaObs    = cat['LAMBDA_OBS'][ ar_cut ]
		ar_delta        = cat['DELTA'][ ar_cut ]
		log_delta_ivar  = numpy.log10(cat['DELTA_IVAR'][ar_cut])
		ar_weight       = numpy.power(ar_lambdaObs/(lambdaRFLya__*onePlusZ0__), halfGama__)/(sigma2LSS[loopIdx]+1./(eta[loopIdx]*cat['DELTA_IVAR'][ar_cut]))
	
		### Flux vs. lambda_RF
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaRF,ar_flux, nbBinRFTemplate__,ar_weight)
		template.append( (xxx,yyy,eyyy) )
		
		### Delta vs. lambda_RF
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaRF,ar_delta, nbBinRFTemplate__,ar_weight)
		residualRF.append( (xxx,yyy,eyyy) )
		
		### Delta+1 vs. lambda_RF
		if (loopIdx%2==1):
			meanTransRF.append( (xxx, (yyy+1.)*numpy.interp(xxx,meanTransRF[loopIdx][0], meanTransRF[loopIdx][1]), eyyy) )
		else:
			meanTransRF.append( meanTransRF[loopIdx] )
		
		
		ar_cut          = numpy.logical_and( (ar_lambdaRF>=lambdaRFMin__) , (ar_lambdaRF<lambdaRFMax__) )
		ar_delta        = ar_delta[ar_cut]
		ar_lambdaObs    = ar_lambdaObs[ar_cut]
		log_delta_ivar  = log_delta_ivar[ar_cut]
		ar_weight       = ar_weight[ar_cut]
		
		### Delta vs. lambda_Obs
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaObs,ar_delta, nbBinObs__,ar_weight)
		residualObs.append( (xxx,yyy,eyyy) )
		
		### Delta+1 vs. lambda_Obs
		if (loopIdx%2==0):
			meanTrandObs.append( (xxx, (yyy+1.)*numpy.interp(xxx,meanTrandObs[loopIdx][0], meanTrandObs[loopIdx][1]), eyyy) )
		else:
			meanTrandObs.append( meanTrandObs[loopIdx] )
		
		### Var_delta_pow_-1 vs. log10_delta_ivar
		xxx, yyy, eyyy, nyyy    = Get_TProfile(log_delta_ivar, ar_delta, nbBinWeight__,ar_weight)
		xxx2, yyy2, eyyy2, nyyy = Get_TProfile(log_delta_ivar, ar_delta*ar_delta, nbBinWeight__,ar_weight)

		tmp_bool = (yyy2-yyy*yyy)>0.
		yyy   = yyy[tmp_bool]
		yyy2  = yyy2[tmp_bool]
		xxx2  = xxx2[tmp_bool]
		nyyy  = nyyy[tmp_bool]
		yyy2  = numpy.power(yyy2-yyy*yyy,-1.)
		eyyy2 = numpy.power(yyy2*numpy.sqrt(nyyy),-1.)
		varPipeline.append( ( xxx2,yyy2,eyyy2 ) )
		
		yyy2  = yyy2[numpy.logical_and( (xxx2>-1.5), (xxx2<2.3) )]
		eyyy2 = eyyy2[numpy.logical_and( (xxx2>-1.5), (xxx2<2.3) )]
		xxx2  = xxx2[numpy.logical_and( (xxx2>-1.5), (xxx2<2.3) )]

		### Set minuit
		def chi2(eta,sigma2LSS):
			return numpy.sum( numpy.power((yyy2-numpy.power(sigma2LSS+1./(eta*numpy.power(10,xxx2)),-1.))/eyyy2 ,2.) )
		m = Minuit(chi2, eta=eta[loopIdx], error_eta=0.1, sigma2LSS=sigma2LSS[loopIdx], error_sigma2LSS=0.1, print_level=-1, errordef=0.01) 	
		m.migrad()
			
		eta.append( m.values['eta'] )
		sigma2LSS.append( m.values['sigma2LSS'] )
	
	file_cat.close()



	meanDelta = [0.]
	stdDelta  = [0.]
	for i in range(1,nbLoop+1):
		meanDelta.append( numpy.mean(residualRF[i][1]) )
		stdDelta.append( numpy.mean(residualRF[i][2]) )
	
	### Save results
	path = '/home/gpfs/manip/mnt/bao/hdumasde/Code/Python/Results_allFlat3/'
	aloopIdx = numpy.arange(0,nbLoop+1)
	numpy.savetxt(path + 'meanDelta.txt', zip(aloopIdx, meanDelta))
	numpy.savetxt(path + 'stdDelta.txt',  zip(aloopIdx, stdDelta))
	numpy.savetxt(path + 'eta.txt',       zip(aloopIdx, eta))
	numpy.savetxt(path + 'sigma2LSS.txt', zip(aloopIdx, sigma2LSS))

	numpy.save(path + 'template',          template)
	numpy.save(path + 'residualRF',        residualRF)
	numpy.save(path + 'meanTransRF',       meanTransRF)
	numpy.save(path + 'residualObs',       residualObs)
	numpy.save(path + 'meanTrandObs',      meanTrandObs)
	numpy.save(path + 'varPipeline',       varPipeline )

	print '  < delta >    = ', meanDelta[-1]
	print '  var delta    = ', stdDelta[-1]
	print '  eta          = ', eta[-1]
	print '  sigma^2_LSS  = ', sigma2LSS[-1]
	
	return
def Plot_Results():
	'''
	'''
	
	print
	print "  ---- Plots ----"
	print
	

	### Show only the last step or not
	lastStep = True
	minStep  = 0

	path = '/home/gpfs/manip/mnt/bao/hdumasde/Code/Python/Results_allFlat3/'
	#path = '/home/helion/Documents/ThÃ¨se/Results/RootFile/Results_backup_allDR12/'

	### Cross-correlation

	def plot_data():
		loopIdx = 0
		for el in data:
			if (loopIdx>=minStep):
				plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o", label="step = " + str(loopIdx) )
			loopIdx += 1

	
	### Evolution of < delta > vs. loopIdx
	data = numpy.loadtxt(path+'meanDelta.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="|< delta >|")
	plt.errorbar(data[:,0], data[:,1], marker="o", label="< delta >")
	plt.title(r'', fontsize=40)
	plt.xlabel(r'$step$', fontsize=40)
	plt.ylabel(r'$< \delta >$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()

	print '  < delta >    = ', data[-1,1]
	
	### Evolution of std_delta vs. loopIdx
	data = numpy.loadtxt(path+'stdDelta.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="-")
	plt.title(r'', fontsize=40)
	plt.xlabel(r'$step$', fontsize=40)
	plt.ylabel(r'$\sigma_{\delta}$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()

	print '  var delta    = ', data[-1,1]
	
	### eta vs. loopIdx
	data = numpy.loadtxt(path+'eta.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="-")
	plt.title(r'', fontsize=40)
	plt.xlabel(r'$step$', fontsize=40)
	plt.ylabel(r'$\eta$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()

	print '  eta          = ', data[-1,1]
	
	### sigma^2_LSS vs. loopIdx
	data = numpy.loadtxt(path+'sigma2LSS.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="-")
	plt.title(r'', fontsize=40)
	plt.xlabel(r'$step$', fontsize=40)
	plt.ylabel(r'$\sigma_{LSS}^{2}$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()

	print '  sigma^2_LSS  = ', data[-1,1]

	### Flux vs. lambda_RF
	data = numpy.load(path+'template.npy')
	plot_data()
	plt.title(r'$Template$', fontsize=40)
	plt.xlabel(r'$\lambda_{R.F.}$', fontsize=40)
	plt.ylabel(r'$Norm \, flux$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()

	### Delta vs. lambda_RF
	data = numpy.load(path+'residualRF.npy')
	plot_data()
	plt.title(r'$Residual$', fontsize=40)
	plt.xlabel(r'$\lambda_{R.F.}$', fontsize=40)
	plt.ylabel(r'$< \delta >$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()
	
	### Delta+1 vs. lambda_RF
	data = numpy.load(path+'meanTransRF.npy')
	plot_data()
	plt.title(r'$Correction$', fontsize=40)
	plt.xlabel(r'$\lambda_{R.F.}$', fontsize=40)
	plt.ylabel(r'$< \delta + 1 >$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()
	
	### Delta vs. lambda_Obs
	data = numpy.load(path+'residualObs.npy')
	plot_data()
	plt.title(r'$Residual$', fontsize=40)
	plt.xlabel(r'$\lambda_{Obs}$', fontsize=40)
	plt.ylabel(r'$< \delta >$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()
	
	### Delta+1 vs. lambda_Obs
	data = numpy.load(path+'meanTrandObs.npy')
	plot_data()
	plt.title(r'$Correction$', fontsize=40)
	plt.xlabel(r'$\lambda_{Obs}$', fontsize=40)
	plt.ylabel(r'$< \delta +1>$', fontsize=40)
	myTools.deal_with_plot(False,False,True)
	plt.show()
	
	
	### varPipeline
	eta        = numpy.loadtxt(path+'eta.txt')
	sigma2LSS  = numpy.loadtxt(path+'sigma2LSS.txt')
	data       = numpy.load(path+'varPipeline.npy')
	tmp_range3 = numpy.arange(-3.,6.,9./40 )
	loopIdx = 0	
	for i in range(0,len(sigma2LSS)):
		if (loopIdx>=minStep):
			fit = ( tmp_range3, numpy.power(sigma2LSS[i,1]+1./(eta[i,1]*numpy.power(10,tmp_range3)),-1.), numpy.zeros(len(tmp_range3)) )
			plt.errorbar(numpy.power(10,data[i][0]), data[i][1] ,yerr=data[i][2], marker="o", label="step = " + str(loopIdx) )
			plt.errorbar(numpy.power(10,fit[0]), fit[1] ,yerr=fit[2], marker="o", label="step = " + str(loopIdx) + ', fit' )
		loopIdx += 1
	plt.title(r'', fontsize=40)
	plt.xlabel(r'$\sigma_{pip.}^{-2}$', fontsize=40)
	plt.ylabel(r'$\sigma_{\delta}^{-2}$', fontsize=40)
	plt.tight_layout()
	myTools.deal_with_plot(True, True,True)
	plt.show()
	
	return



########################################################################
###  To get path
########################################################################
	
	
def Get_Path_To_Fits():
	'''
	Return the path to the catalogue
	'''

	if (pipeline__=="DR12"):
		if (location__ == "HOME"):
			path = "/home/helion/Documents/ThÃ¨se/Data/Fits/Spectra/spec-"
		elif (location__ == "ICLUST"):
			path = "/home/gpfs/manip/mnt0607/bao/Spectra/SpectraV5_7_0Bailey/"
	elif (pipeline__=='Guy' or pipeline__=='Margala'):
		path = '/home/gpfs/manip/mnt0607/bao/Spectra/SpectraV5_8_guy/spectra/'
	elif (pipeline__=="MOCK"):
		if (location__ == "ICLUST"):
			path = "/home/gpfs/manip/mnt0607/bao/MockV4/M3_0_" + str(chunckNb__) + '/' + str(simulNb__).zfill(3) + '/'
	elif (pipeline__ == 'eBOSS'):
			path = "/home/gpfs/manip/mnt0607/bao/Spectra/SpectraV5_8_0/"
	
	print '  Path to specFiles = ', path	
	return path			
def Get_Path_To_Save_New_Fits(iStart=0,iEnd=-1):
	'''
	Return the path to the catalogue
	'''
	
	if (iEnd==-1):
		endString = '.fits'
	else:
		endString = '_'+str(iStart)+'_'+str(iEnd)+'.fits'

	if (location__ == "HOME"):
		return
	if (pipeline__=='DR12'):
		if (not reObs__):
			path = "/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/allDR12_test" + endString
		else:
			path = "/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/DR12_reObs" + endString
	elif (pipeline__=='Guy'):
		path = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/DR12_Guy' + endString
	elif (pipeline__=='Margala'):
		path = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/DR12_Margala' + endString
	elif (pipeline__=='eBOSS'):
		path = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/eBOSS' + endString
	elif (pipeline__=='MOCK'):
		path = "/home/gpfs/manip/mnt/bao/MockV4_Production_withOwnTemplate/M3_0_" + str(chunckNb__) + '_python/' + str(simulNb__).zfill(3) +'/Mock__DR11' + endString
		
	print '  Path where to save production fits file = ', path
	return path
def Get_Data_Fits_File():
	'''
	Return the folder and the path to the catalogue
	'''
	
	if (pipeline__=="DR12"):
		if (location__ == "HOME"):
			folder = '/home/helion/Documents/ThÃ¨se/Results/RootFile/'
			path   = folder + 'allDR12_test'
		elif (location__ == "ICLUST"):
			folder = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/'
			path   = folder + 'allDR12.fits'
	elif (pipeline__=="MOCK"):
		if (location__ == "ICLUST"):
			folder = '/home/gpfs/manip/mnt/bao/MockV4_Production_withOwnTemplate/M3_0_' + str(chunckNb__) + '_python/' + str(simulNb__).zfill(3) + '/'
			path   = folder + 'allMock.fits'
		
	print '  Path where to get data fits folder = ', folder
	print '  Path where to get data fits file   = ', path
	return [folder,path]
def Get_Catalogue():
	'''
	'''

	plate_mjd_fiber_list = []
	
	if (location__ == "HOME"):
		return
	
	if (pipeline__=="DR12" or pipeline__=='Guy' or pipeline__=='Margala'):
		path = "/home/gpfs/manip/mnt/bao/hdumasde/Lists/DR12Q_v2_10.fits"
	elif (pipeline__ == 'eBOSS'):
		path = "/home/gpfs/manip/mnt/bao/Spectra/spAll-v5_8_0.fits"
	elif (pipeline__=="MOCK"):
		path = "/home/gpfs/manip/mnt/bao/hdumasde/CrossCorrelation_StartingAgainFrom1347/CrossCorrelation/List/DR11MultipleOfficial.txt"
	print path		
			
	if (pipeline__=='DR12' or pipeline__=='Guy' or pipeline__=='Margala'):
		file_cat_allForest = pyfits.open(path, memmap=True )
		
		cat_allForest = file_cat_allForest[1].data
		print "  The size of the catalogue is           : " + str(len(cat_allForest))
		cat_allForest = cat_allForest[ cat_allForest["BAL_FLAG_VI"]==0]
		print "  We keep BAL_FLAG_VI == 0 , the size is : " + str(len(cat_allForest))
		cat_allForest = cat_allForest[ cat_allForest["Z_VI"]>minRedshift__]
		print "  We keep Z_VI > " + str(minRedshift__) + "  , the size is      : " + str(len(cat_allForest))
		cat_allForest = cat_allForest[ cat_allForest["Z_VI"]<=maxRedshift__]
		print "  We keep Z_VI <= " + str(maxRedshift__) + "  , the size is      : " + str(len(cat_allForest))
		

		if (dataFitsType__=='spPlate'):
			### Get the sorted list of plates
			plate_list = []
			for i in cat_allForest['PLATE']:
				if i not in plate_list:
					plate_list.append(i)
			plate_list = numpy.sort(plate_list)

			### Get the list of couple plate, mjd
			plate_mjd_list = []
			for i in plate_list:
				MJD_list = []
				for j in cat_allForest['MJD'][ cat_allForest['PLATE']==i ]:
					if j not in MJD_list:
						MJD_list.append(j)
				for j in MJD_list:
					plate_mjd_list.append( (i,j) )
			plate_mjd_list = numpy.asarray(plate_mjd_list)

			### Get a list where each line is a couple plate, mjd than all the fibers
			plate_mjd_fiber_list = []
		
			for i in plate_mjd_list:
				tmp_list2 = numpy.sort( cat_allForest['FIBERID'][ numpy.logical_and(cat_allForest['PLATE']==i[0],cat_allForest['MJD']==i[1]) ] )
				plate_mjd_fiber_list.append(numpy.concatenate([i,tmp_list2]))


		plate = cat_allForest['PLATE']
		mjd   = cat_allForest['MJD']
		fiber = cat_allForest['FIBERID']
		ra    = cat_allForest['RA']
		dec   = cat_allForest['DEC']
		z     = cat_allForest['Z_VI']
		totalObs = len(plate)

		if (reObs__):
			plate_reObs = []
			mjd_reObs   = []
			fiber_reObs = []
			ra_reObs    = []
			dec_reObs   = []
			z_reObs     = []

			### Get re-observations
			cat_allForest   = cat_allForest[ cat_allForest['NSPEC_BOSS']>0 ]
			print '   Number of reobserved quasares = ', len(cat_allForest)
			for el in cat_allForest:
				for i in range(0,el['NSPEC_BOSS']):
					plate_reObs.append(el['PLATE_DUPLICATE'][i])
					mjd_reObs.append(el['MJD_DUPLICATE'][i])
					fiber_reObs.append(el['FIBERID_DUPLICATE'][i])
					ra_reObs.append(el['RA'])
					dec_reObs.append(el['DEC'])
					z_reObs.append(el['Z_VI'])

			plate = plate_reObs
			mjd   = mjd_reObs
			fiber = fiber_reObs
			ra    = ra_reObs
			dec   = dec_reObs
			z     = z_reObs

		print '  Number of additionnals observations = ',len(plate)-totalObs
		
		del cat_allForest
		del file_cat_allForest
	elif (pipeline__ == 'eBOSS'):
		redShiftKey = 'Z'
		cat = pyfits.open(path)[1].data
		print "  The size of the catalogue is           : ", len(cat)
		cat = cat[ cat[redShiftKey]>minRedshift__]
		print "  We keep Z > " + str(minRedshift__) + "  , the size is      : ", len(cat)
		cat = cat[ cat[redShiftKey]<=maxRedshift__]
		print "  We keep Z <= " + str(maxRedshift__) + "  , the size is      : ", len(cat)
		cat = cat[ cat['CLASS'] == 'QSO' ]
		print '  We keep CLASS == QSO, the size is      : ', len(cat)
		cat = cat[ cat['ZWARNING'] == 0 ]
		print '  We keep ZWARNING == 0, the size is      : ', len(cat)
		cat = cat[ cat['Z_ERR'] > 0 ]
		print '  We keep Z_ERR > 0, the size is      : ', len(cat)

		if (dataFitsType__=='spPlate'):
			### Get the sorted list of plates
			plate_list = []
			for i in cat['PLATE']:
				if i not in plate_list:
					plate_list.append(i)
			plate_list = numpy.sort(plate_list)

			### Get the list of couple plate, mjd
			plate_mjd_list = []
			for i in plate_list:
				MJD_list = []
				for j in cat['MJD'][ cat['PLATE']==i ]:
					if j not in MJD_list:
						MJD_list.append(j)
				for j in MJD_list:
					plate_mjd_list.append( (i,j) )
			plate_mjd_list = numpy.asarray(plate_mjd_list)

			### Get a list where each line is a couple plate, mjd than all the fibers
			plate_mjd_fiber_list = []
		
			for i in plate_mjd_list:
				tmp_list2 = numpy.sort( cat['FIBERID'][ numpy.logical_and(cat['PLATE']==i[0],cat['MJD']==i[1]) ] )
				plate_mjd_fiber_list.append(numpy.concatenate([i,tmp_list2]))

		plate = cat['PLATE']
		mjd   = cat['MJD']
		fiber = cat['FIBERID']
		ra    = cat['RA']
		dec   = cat['DEC']
		z     = cat['Z']

	elif (pipeline__=="MOCK"):
		
		tmp_data = numpy.loadtxt(path)
		plate = tmp_data[:,0].astype('int')
		mjd   = tmp_data[:,1].astype('int')
		fiber = tmp_data[:,2].astype('int')
		ra    = tmp_data[:,3]
		dec   = tmp_data[:,4]
		z     = tmp_data[:,5]

		print '  ', len(plate)
		
		tmp_bool = numpy.logical_end( (z>minRedshift__), (z<=maxRedshift__) )
		plate = plate[tmp_bool]
		mjd   = mjd[tmp_bool]
		fiber = fiber[tmp_bool]
		ra    = ra[tmp_bool]
		dec   = dec[tmp_bool]
		z     = z[tmp_bool]

		print '  ', len(plate)	
		
	data = numpy.asarray( zip(plate, mjd, fiber, ra, dec, z) )
	return data, plate_mjd_fiber_list

iStart = 0
iEnd   = 0

if (len(sys.argv)>=5):

	iStart     = int(sys.argv[1])
	iEnd       = int(sys.argv[2])
	chunckNb__ = int(sys.argv[3])
	simulNb__  = int(sys.argv[4])

#make_all_Fits(iStart,iEnd)
#Merge_Files()
#profile.run('print Get_Template(); print',sort=2)
Get_Template()
Plot_Results()
#Convert_Fits_To_Ntuples()
#read_data_from_root()

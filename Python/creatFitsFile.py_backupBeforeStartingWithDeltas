# -*- coding: utf-8 -*-
#
# created by Hélion du Mas des Bourboux
# <helion331990@gmail.com>



import subprocess
import sys
import os

import astropy.io.fits as pyfits
import numpy
import matplotlib.pyplot as plt
#import matplotlib.patches as mpatches
#import decimal
#import profile
from iminuit import Minuit
#import root_numpy
#import ROOT
#import array

#import warnings
#warnings.filterwarnings("error")

### "HOME" or "ICLUST"
location__ = 'ICLUST'
### "DR12" or "MOCK"
pipeline__ = 'DR12'

### Parameter if simulation
chunckNb__ = 0
simulNb__  = 0

bit16__ = 65536
lenSpectrum = 4619

### Lambda_{R.F.}
########################################################################

### Observed wavelenght range
lambdaObsMin__ = 3600.
lambdaObsMax__ = 7235.
log10lambdaObsMin__ = numpy.log10(lambdaObsMin__)
log10lambdaObsMax__ = numpy.log10(lambdaObsMax__)

### Sky lines
#############
skyLines__ = [ (3615,3619),(3932,3937),(3966,3972),(4042,4050),
	(4357,4362),(5458,5467),(5573,5585),(5682,5695),
	(5885,5902),(6235,6241),(6256,6263),(6296,6311),
	(6320,6334),(6362,6369),(6498,6502),(6554,6557),
	(6825,6840),(6862,6870),(6922,6928),(6948,6954),
	(6977,6982) ]
skyLines__ = numpy.log10(skyLines__)

### Nuber of bin for mean transmission flux
nbBinObs__ = int((lambdaObsMax__-lambdaObsMin__)/1.)

########################################################################
### Lambda_{R.F.}
########################################################################

### Rest Frame wavelenght range for template
lambdaRFTemplateMin__ = 1037.
lambdaRFTemplateMax__ = 1203.
log10lambdaRFTemplateMin__ = numpy.log10(lambdaRFTemplateMin__)
log10lambdaRFTemplateMax__ = numpy.log10(lambdaRFTemplateMax__)

### Rest Frame wavelenght range for data
lambdaRFMin__ = 1040.
lambdaRFMax__ = 1200.

### Normalisation region
lambdaRFNormaMin__ = 1275.
lambdaRFNormaMax__ = 1285.
log10lambdaRFNormaMin__ = numpy.log10(lambdaRFNormaMin__)
log10lambdaRFNormaMax__ = numpy.log10(lambdaRFNormaMax__)

### Lyman-alpha line
lambdaRFLya__ = 1215.67

### Min and max number of pixels in the forest
nbBinRFMin__ = 50
nbBinRFMax__ = 700

### Nuber of bin for template
nbBinRFTemplate__ = int((lambdaRFTemplateMax__-lambdaRFTemplateMin__)/1.)


########################################################################

### Minimal redshift to get first pixel
minRedshift__ = lambdaObsMin__/lambdaRFMax__ - 1.
maxRedshift__ = lambdaObsMax__/lambdaRFNormaMin__ - 1.

### Number of pixel for the weight
nbBinWeight__ = 100

### Global variable for minuit
#m_data = []
#m_inter = []


def make_all_Fits(iStart=0,iEnd=-1):

	tmp_string = "\n   ---- Starting ---- \n\n  iStart = " + str(iStart) + "  iEnd = " + str(iEnd) + "\n"

	tmp_command = "echo \"" + tmp_string + "\""
	subprocess.call(tmp_command, shell=True)

	### Path to the folder where all spectra are
	pathToSpec = Get_Path_To_Fits()
	
	### Get the catalogue
	data,iStart,iEnd  = Get_Catalogue(iStart,iEnd)
	
	
	sizeMax = len(data[0])
	if (iEnd!=-1):
		if (iEnd>sizeMax):
			iEnd=sizeMax
		if (iStart>sizeMax):
			print '  iStart>sizeMax'
			return
		iEnd += 1
		data = [ data[0][iStart:iEnd],data[1][iStart:iEnd],data[2][iStart:iEnd],data[3][iStart:iEnd],data[4][iStart:iEnd],data[5][iStart:iEnd] ]
	
	sizeMax = len(data[0])

	tmp_command = "echo \"" + "  Final length = "+ str(sizeMax) + "\""
	subprocess.call(tmp_command, shell=True)

	tmp_command = "echo  \"" + "\n  Creating the FITS file" + "\""
	subprocess.call(tmp_command, shell=True)

	### Create a FITS file with only the usefull data
	plate                = pyfits.Column(name='PLATE',           format='J', array=data[0] )
	mjd                  = pyfits.Column(name='MJD',             format='J', array=data[1] )
	fiber                = pyfits.Column(name='FIBERID',         format='J', array=data[2] )
	
	ra                   = pyfits.Column(name='RA',              format='D',    unit='deg', array=data[3] )
	de                   = pyfits.Column(name='DEC',             format='D',    unit='deg', array=data[4] )
	zz                   = pyfits.Column(name='Z_VI',            format='D', array=data[5] )
	nb                   = pyfits.Column(name='NB_PIXEL',        format='I', array=numpy.zeros(sizeMax) )
	
	tmp_nbBinForest     = str(nbBinRFMax__)+'D'
	lambdaForest        = pyfits.Column(name='LAMBDA_OBS',       format=tmp_nbBinForest, unit='angstrom', array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	lambdaRFForest      = pyfits.Column(name='LAMBDA_RF',        format=tmp_nbBinForest, unit='angstrom', array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	normFluxForest      = pyfits.Column(name='NORM_FLUX',        format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	normFluxIvarForest  = pyfits.Column(name='NORM_FLUX_IVAR',   format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	deltaForest         = pyfits.Column(name='DELTA',            format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	deltaIvarForest     = pyfits.Column(name='DELTA_IVAR',       format=tmp_nbBinForest, array=numpy.zeros((sizeMax,nbBinRFMax__)) )
	
	del data
	
	ar_normFactor = []
	len_forest    = []
	
	tbhdu = pyfits.BinTableHDU.from_columns([plate, mjd, fiber, ra, de, zz, nb, lambdaForest, lambdaRFForest, normFluxForest, normFluxIvarForest, deltaForest, deltaIvarForest])
	cat_tbhdu = tbhdu.data
	
	tmp_command = "echo  \"" + "\n  Starting the loop\n\n" + "\""
	subprocess.call(tmp_command, shell=True)
	
	### Read and write in the FITS file
	for el in cat_tbhdu:
			
		try:
			#cat = pyfits.open(pathToSpec + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits", memmap=True)[1].data
			cat = pyfits.open(pathToSpec + str(el['PLATE']) + "/spec-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits", memmap=True)[1].data
			#cat = pyfits.open(pathToSpec + str(el['PLATE']) + "/mock-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits", memmap=True)[1].data
		except Exception,error:
			#tmp_string = pathToSpec + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits"
			tmp_string = pathToSpec + str(el['PLATE']) + "/spec-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits"
			#tmp_string = pathToSpec + str(el['PLATE']) + "/mock-" + str(el['PLATE']) + "-" + str(el['MJD']) + "-" + str(el['FIBERID']).zfill(4) + ".fits"

			tmp_command = "echo  \"" + "  File not found \n " + tmp_string + "\""
			subprocess.call(tmp_command, shell=True)
			tmp_command = "echo  \"  " + str(error)  + "\n\""
			subprocess.call(tmp_command, shell=True)

			ar_normFactor += [-1.]
			len_forest    += [-1.]
			continue
			
		### Apply cuts for bad pixels
		############################## 
		
		### CCD and too many sky lines
		cat = cat[ (numpy.logical_and( (cat["LOGLAM"]>=log10lambdaObsMin__) , (cat["LOGLAM"]<log10lambdaObsMax__) )) ]
		### Sky Lines
		for lines in skyLines__:
			cat = cat[ (numpy.logical_or( (cat["LOGLAM"]<=lines[0]) , (cat["LOGLAM"]>=lines[1]) )) ]
		cat = cat[ numpy.logical_and( numpy.logical_and( (cat["IVAR"]>0.), (cat["AND_MASK"]<bit16__)), (numpy.isfinite(cat["FLUX"])) ) ]
	
		### Get wher to cut for lambda_RF_Norma
		tmp_logZ = numpy.log10(1.+el['Z_VI'])
		
		### Get the normalisation factor
		try:
			normFactor = numpy.mean( cat["FLUX"][ numpy.logical_and( (cat["LOGLAM"]>log10lambdaRFNormaMin__+tmp_logZ), (cat["LOGLAM"]<log10lambdaRFNormaMax__+tmp_logZ) ) ] )
		except Exception,error:
			tmp_command = "echo  \"" + "  Error in: 'normFactor = numpy.mean',  z = " + str(el['Z_VI']) + ", idx = " + str(len(ar_normFactor)+iStart) + "\""
			subprocess.call(tmp_command, shell=True)
			tmp_command = "echo  \"  " + str(error)  + "\n\""
			subprocess.call(tmp_command, shell=True)
			ar_normFactor += [-1.]
			len_forest    += [-1.]
			continue

		ar_normFactor += [normFactor]
	
		### Apply cuts to keep only the forest
		cat = cat[ numpy.logical_and( (cat["LOGLAM"]>=log10lambdaRFTemplateMin__+tmp_logZ) , (cat["LOGLAM"]<log10lambdaRFTemplateMax__+tmp_logZ) ) ]
		
		### Find the number of pixels
		tmp_lenCat = len(cat)
		el['NB_PIXEL'] = tmp_lenCat
		
		### Store the data
		el['NORM_FLUX'][:tmp_lenCat]      = cat["FLUX"]/normFactor
		el['NORM_FLUX_IVAR'][:tmp_lenCat] = cat["IVAR"]*normFactor*normFactor
		el['LAMBDA_OBS'][:tmp_lenCat]     = numpy.power(10., cat["LOGLAM"])
		el['LAMBDA_RF'][:tmp_lenCat]      = numpy.power(10., cat["LOGLAM"])/(1.+el['Z_VI'])

		len_forest += [ len( el['LAMBDA_RF'][numpy.logical_and( (el['LAMBDA_RF']>=lambdaRFMin__) , (el['LAMBDA_RF']<lambdaRFMax__) )]) ]				
				
	print "\n  Number of forest             : " + str(len(cat_tbhdu))
	
	ar_normFactor = numpy.asarray(ar_normFactor)
	len_forest = numpy.asarray(len_forest)

	print len(cat_tbhdu)
	print len((ar_normFactor>0.))
	print len(numpy.isfinite(ar_normFactor))
	print len((len_forest>=nbBinRFMin__))

	cat_tbhdu = cat_tbhdu[ numpy.logical_and( numpy.logical_and((ar_normFactor>0.),(numpy.isfinite(ar_normFactor))), (len_forest>=nbBinRFMin__)) ]
	print '  ', len(cat_tbhdu)
	cat_tbhdu = cat_tbhdu[ (cat_tbhdu['NB_PIXEL'] >= nbBinRFMin__) ]
	print '  ', len(cat_tbhdu)
	print   "  Number of forest after cut   : " + str(len(cat_tbhdu))
	
	tbhdu = pyfits.BinTableHDU(data=cat_tbhdu)
	tbhdu.update()

	tbhdu.writeto(Get_Path_To_Save_New_Fits(iStart,iEnd), clobber=True)

	print "\n\n\n"
	return
	
def Merge_Files():
	
	where = Get_Data_Fits_File()
	folder = where[0]
	path   = where[1]
	if (pipeline__=='DR12'):
		scheme = "allDR12_test_"
	elif (pipeline__=='MOCK'):
		scheme = "Mock__DR11_"
	lenScheme = len(scheme)
	
	all_t = os.listdir(folder)
	
	### Get the FitsFile
	all_t_file  = []
	for el in all_t:
		if (el[:lenScheme]==scheme):
			all_t_file  += [pyfits.open(folder+el,  memmap=True)]
			print folder+el
	
	### Get arrays of size of FitsFile
	all_t_nrows = []
	for el in all_t_file:
		all_t_nrows += [ el[1].data.shape[0] ]
	nrowsTot = numpy.sum(all_t_nrows)

	print 
	print len(all_t_nrows)
	print nrowsTot

	### Set the Fits_File which will contain all
	hdu = pyfits.BinTableHDU.from_columns(all_t_file[0][1].columns, nrows=nrowsTot)

	### Set the values of each rows
	first = 0
	last  = all_t_nrows[0]
	for i in range(1, len(all_t_nrows)):
		first += all_t_nrows[i-1]
		last  += all_t_nrows[i]
		print first, last
		for colname in all_t_file[0][1].columns.names:
			hdu.data[colname][first:last] = all_t_file[i][1].data[colname]
	
	## Map
	plt.plot(hdu.data["RA"], hdu.data["DEC"], linestyle="", marker="o")
	plt.show()

	hdu.writeto(path, clobber=True)

	return
def Get_Template():
	'''
	'''
	
	nbLoop = 10
	
	### Use weight or not
	useWeight = True
	ar_weight = []

	### Min value for DELTA_IVAR
	minDeltaIvar__ = 0.001
	
	### List to histograms at each steps
	meanDelta         = []
	stdDelta          = []
	eta               = [1.]
	sigma2LSS         = [0.1]

	template          = []
	residualRF        = []
	residualObs       = []
	meanTransRF       = []
	meanTrandObs      = []
	templateCorrected = []
	varPipeline       = []
	aloopIdx          = range(0,nbLoop)
	
	### Get Data
	####################################################################
	### ,mode='update' ##, memmap=True
	where = Get_Data_Fits_File()
	path  = where[1]
	file_cat = pyfits.open(path)
	print len(file_cat[1].data)
	cat = file_cat[1].data[:100]
	print len(cat)
	
	for loopIdx in aloopIdx:
		
		tmp_command = "echo  \"  " +  "  ---- " + str(loopIdx) + " ---- " + "\n\""
		subprocess.call(tmp_command, shell=True)		
		
		### Set arrays
		################################################################
		ar_cut          = (cat['NORM_FLUX_IVAR']>0.)
		if (loopIdx>0):
			ar_cut = numpy.logical_and( ar_cut, (cat['DELTA_IVAR']>minDeltaIvar__) )
		
		ar_flux         = cat['NORM_FLUX'][ ar_cut ]
		ar_lambdaRF     = cat['LAMBDA_RF'][ ar_cut ]
		ar_lambdaObs    = cat['LAMBDA_OBS'][ ar_cut ]
		len_ar_flux = len(ar_flux)
		if (loopIdx<1):
			ar_weight       = numpy.ones(len_ar_flux)
		else:
			ar_weight       = 1./(sigma2LSS[loopIdx-1]+1./(eta[loopIdx-1]*cat['DELTA_IVAR'][ar_cut]))

		if (loopIdx<1):
			log_delta_ivar  = numpy.ones(len_ar_flux)
			ar_delta        = numpy.zeros(len_ar_flux)
		else:
			log_delta_ivar  = numpy.log10(cat['DELTA_IVAR'][ar_cut])
			ar_delta        = cat['DELTA'][ ar_cut ]

	
		### Flux vs. lambda_RF
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaRF,ar_flux, nbBinRFTemplate__,useWeight,ar_weight)
		template += [(xxx,yyy,eyyy)]
		
		### Delta vs. lambda_RF
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaRF,ar_delta, nbBinRFTemplate__,useWeight,ar_weight)
		residualRF += [(xxx,yyy,eyyy)]
		
		### Delta+1 vs. lambda_RF
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaRF,ar_delta+1., nbBinRFTemplate__,useWeight,ar_weight)
		if (loopIdx==0):
			meanTransRF += [(xxx,yyy,eyyy)]
		elif (loopIdx%2==1):
			meanTransRF += [(xxx, yyy*numpy.interp(xxx,meanTransRF[loopIdx-1][0], meanTransRF[loopIdx-1][1]), eyyy)]
		else:
			meanTransRF += [meanTransRF[loopIdx-1]]
		
		
		ar_cut = numpy.logical_and( (ar_lambdaRF>=lambdaRFMin__) , (ar_lambdaRF<lambdaRFMax__) ) 
		ar_flux         = ar_flux[ar_cut]
		ar_delta        = ar_delta[ar_cut]
		ar_lambdaRF     = ar_lambdaRF[ar_cut]
		ar_lambdaObs    = ar_lambdaObs[ar_cut]
		log_delta_ivar  = log_delta_ivar[ar_cut]
		ar_weight       = ar_weight[ar_cut]
		
		### Delta vs. lambda_Obs
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaObs,ar_delta, nbBinObs__,useWeight,ar_weight)
		residualObs += [(xxx,yyy,eyyy)]
		
		### Delta+1 vs. lambda_Obs
		xxx, yyy, eyyy, nyyy = Get_TProfile(ar_lambdaObs,ar_delta+1., nbBinObs__,useWeight,ar_weight)
		if (loopIdx==0):
			meanTrandObs += [(xxx,yyy,eyyy)]
		elif (loopIdx%2==1):
			meanTrandObs += [ meanTrandObs[loopIdx-1] ]
		else:
			meanTrandObs += [(xxx, yyy*numpy.interp(xxx,meanTrandObs[loopIdx-1][0], meanTrandObs[loopIdx-1][1]), eyyy)]
		
		
		### Var_delta_pow_-1 vs. log10_delta_ivar
		xxx, yyy, eyyy, nyyy    = Get_TProfile(log_delta_ivar, ar_delta, nbBinWeight__,useWeight,ar_weight)
		xxx2, yyy2, eyyy2, nyyy = Get_TProfile(log_delta_ivar, ar_delta*ar_delta, nbBinWeight__,useWeight,ar_weight)

		tmp_bool = (yyy2-yyy*yyy)>0.
		yyy   = yyy[tmp_bool]
		yyy2  = yyy2[tmp_bool]
		xxx2  = xxx2[tmp_bool]
		nyyy  = nyyy[tmp_bool]
		yyy2  = numpy.power(yyy2-yyy*yyy,-1.)
		eyyy2 = numpy.power(yyy2*numpy.sqrt(nyyy),-1.)
		varPipeline += [( xxx2,yyy2,eyyy2 )]
		
		yyy2  = yyy2[numpy.logical_and( (xxx2>-1.5), (xxx2<2.3) )]
		eyyy2 = eyyy2[numpy.logical_and( (xxx2>-1.5), (xxx2<2.3) )]
		xxx2  = xxx2[numpy.logical_and( (xxx2>-1.5), (xxx2<2.3) )]
		
		if (loopIdx>0):
			### Set minuit
			def chi2(eta,sigma2LSS):
				return numpy.sum( numpy.power((yyy2-numpy.power(sigma2LSS+1./(eta*numpy.power(10,xxx2)),-1.))/eyyy2 ,2.) )
			m = Minuit(chi2, eta=eta[loopIdx-1], sigma2LSS=sigma2LSS[loopIdx-1], error_eta=0.1, error_sigma2LSS=0.1, print_level=-1, errordef=0.01) 	
			m.migrad()
			
			eta       += [m.values['eta']]
			sigma2LSS += [m.values['sigma2LSS']]
		
		### templateCorrected
		if (loopIdx==0):
			templateCorrected += [ template[0] ]
		else:
			templateCorrected += [( template[loopIdx][0], template[loopIdx][1]*numpy.interp(template[loopIdx][0],meanTransRF[loopIdx][0],meanTransRF[loopIdx][1]), template[loopIdx][2] )]
			
			
		### Print results
		meanDelta += [numpy.average(ar_delta,weights=ar_weight)]
		stdDelta  += [numpy.average( (ar_delta-meanDelta[loopIdx])**2.,weights=ar_weight)]		
		
		
		### Find delta of catalogue
		for el in cat:
			tmp_lenCat = el['NB_PIXEL']
			'''
			### If delta vs. lambda_RF flat
			tmp_interp             = numpy.interp(el['LAMBDA_RF'][:tmp_lenCat], templateCorrected[loopIdx][0], templateCorrected[loopIdx][1])
			
			### If delta vs. lambda_Obs flat
			#tmp_interp            = numpy.interp(el['LAMBDA_RF'][:tmp_lenCat], template[loopIdx][0], template[loopIdx][1])
			tmp_interp             = numpy.multiply(tmp_interp,numpy.interp(el['LAMBDA_OBS'][:tmp_lenCat], meanTrandObs[loopIdx][0], meanTrandObs[loopIdx][1]))
			'''
			### If (delta vs. lambda_RF) and (delta vs. lambda_Obs) flat
			tmp_interp             = numpy.interp(el['LAMBDA_RF'][:tmp_lenCat], templateCorrected[loopIdx][0], templateCorrected[loopIdx][1])
				
			if (loopIdx<1):
				ar_weight = 1.
			else:
				ar_weight = 1./(sigma2LSS[loopIdx-1]+1./(eta[loopIdx-1]*el['DELTA_IVAR'][:tmp_lenCat]))
				
			### Set minuit
			def chi2(alpha):
				#return numpy.sum(numpy.power(el['NORM_FLUX'][:tmp_lenCat]-(alpha)*tmp_interp,2.))
				#return numpy.sum(numpy.power(el['NORM_FLUX'][:tmp_lenCat]-(alpha+beta*el['LAMBDA_RF'][:tmp_lenCat])*tmp_interp,2.))
				return numpy.sum(numpy.power((el['NORM_FLUX'][:tmp_lenCat]-alpha*tmp_interp)/ar_weight,2.))

			m = Minuit(chi2, alpha=1.,error_alpha=1., print_level=-1, pedantic=False)
			#m = Minuit(chi2, alpha=1., beta=0., error_alpha=0.1, error_beta=0.1, print_level=-1, pedantic=False)
			m.migrad()
				
				
			tmp_interp = m.values['alpha']*tmp_interp
			#tmp_interp = (m.values['alpha']+m.values['beta']*el['LAMBDA_RF'][:tmp_lenCat])*tmp_interp
			tmp_interp             = tmp_interp*numpy.interp(el['LAMBDA_OBS'][:tmp_lenCat], meanTrandObs[loopIdx][0], meanTrandObs[loopIdx][1])

			el['DELTA'][:tmp_lenCat]        = el['NORM_FLUX'][:tmp_lenCat]/tmp_interp-1.
			el['DELTA_IVAR'][:tmp_lenCat]   = el['NORM_FLUX_IVAR'][:tmp_lenCat]*tmp_interp*tmp_interp

			'''
			plt.errorbar(el['LAMBDA_RF'][:tmp_lenCat], el['NORM_FLUX'][:tmp_lenCat], marker="o", label='data' )
			plt.errorbar(el['LAMBDA_RF'][:tmp_lenCat], tmp_interp, marker="o", label='interpolation' )
			plt.errorbar(el['LAMBDA_RF'][:tmp_lenCat], tmp_cont, marker="o", label='model' )
			plt.show()
			'''
	
	file_cat.close()
	
	path = '/home/gpfs/manip/mnt/bao/hdumasde/Code/Python/Results/'
	numpy.savetxt(path + 'meanDelta.txt', zip(aloopIdx, meanDelta))
	numpy.savetxt(path + 'stdDelta.txt',  zip(aloopIdx, stdDelta))
	numpy.savetxt(path + 'eta.txt',       zip(aloopIdx, eta))
	numpy.savetxt(path + 'sigma2LSS.txt', zip(aloopIdx, sigma2LSS))

	numpy.save(path + 'template',          template)
	numpy.save(path + 'residualRF',        residualRF)
	numpy.save(path + 'meanTransRF',       meanTransRF)
	numpy.save(path + 'residualObs',       residualObs)
	numpy.save(path + 'meanTrandObs',      meanTrandObs)
	numpy.save(path + 'templateCorrected', templateCorrected)
	numpy.save(path + 'varPipeline',       varPipeline )

	return
def Plot_Results():
	'''
	'''

	print "  ---- Plots ----"

	

	### Show only the last step or not
	lastStep = True

	path = '/home/gpfs/manip/mnt/bao/hdumasde/Code/Python/Results/'
	
	### Evolution of < delta > vs. loopIdx
	data = numpy.loadtxt(path+'meanDelta.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="abs(<delta>)")
	plt.errorbar(data[:,0], data[:,1], marker="o", label="<delta>")
	deal_with_plot('idx of loop', '|< delta >|', '')
	plt.show()
	
	### Evolution of std_delta vs. loopIdx
	data = numpy.loadtxt(path+'stdDelta.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="-")
	deal_with_plot('idx of loop', 'std delta', '')
	plt.show()
	
	### eta vs. loopIdx
	data = numpy.loadtxt(path+'eta.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="-")
	deal_with_plot('idx of loop', 'eta', '')
	plt.show()

	print '  eta         = ', data[-1,1]
	
	### sigma^2_LSS vs. loopIdx
	data = numpy.loadtxt(path+'sigma2LSS.txt')
	plt.errorbar(data[:,0], numpy.fabs(data[:,1]), marker="o", label="-")
	deal_with_plot('idx of loop', 'sigma^2_LSS', '')
	plt.show()

	print '  sigma^2_LSS = ', data[-1,1]
	
	### Flux vs. lambda_RF
	data = numpy.load(path+'template.npy')
	loopIdx = 0
	for el in data:
		if (lastStep and loopIdx==len(data)-1):
			plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o", label="step = " + str(loopIdx) )
		loopIdx += 1
	deal_with_plot('lambda_RF', 'Flux', 'Template')
	plt.show()

	### Delta vs. lambda_RF
	data = numpy.load(path+'residualRF.npy')
	loopIdx = 0
	for el in data:
		if (lastStep and loopIdx==len(data)-1):
			plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o", label="step = " + str(loopIdx) )
		loopIdx += 1
	deal_with_plot('lambda_RF', 'Delta', 'residualRF')
	plt.show()
	
	### Delta+1 vs. lambda_RF
	data = numpy.load(path+'meanTransRF.npy')
	loopIdx = 0
	for el in data:
		if (lastStep and loopIdx==len(data)-1):
			plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o", label="step = " + str(loopIdx) )
		loopIdx += 1
	deal_with_plot('lambda_RF', 'Delta+1', 'meanTransRF')
	plt.show()
	
	### Delta vs. lambda_Obs
	data = numpy.load(path+'residualObs.npy')
	loopIdx = 0
	for el in data:
		if (lastStep and loopIdx==len(data)-1):
			plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o", label="step = " + str(loopIdx) )
		loopIdx += 1
	deal_with_plot('lambda_Obs', 'Delta', 'residualObs')
	plt.show()
	
	### Delta+1 vs. lambda_Obs
	data = numpy.load(path+'meanTrandObs.npy')
	loopIdx = 0
	for el in data:
		if (lastStep and loopIdx==len(data)-1):
			plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o", label="step = " + str(loopIdx) )
		loopIdx += 1
	deal_with_plot('lambda_Obs', 'Delta+1', 'meanTrandObs')
	plt.show()
	
	
	### templateCorrected
	data = numpy.load(path+'templateCorrected.npy')
	loopIdx = 0
	for el in data:
		if (lastStep and loopIdx==len(data)-1):
			plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o", label="step = " + str(loopIdx) )
		loopIdx += 1
	deal_with_plot('lambda_Obs', 'Delta+1', 'templateCorrected')
	plt.show()
	
	
	### varPipeline
	data = numpy.load(path+'varPipeline.npy')
	loopIdx = 0
	for el in data:
		if (len(el[0])>1):
			if (lastStep and loopIdx==len(data)-1):
				plt.errorbar(el[0], el[1] ,yerr=el[2], marker="o",label="step = "+str(loopIdx) )
		loopIdx += 1
	deal_with_plot('log10_IVar_pipeline', 'IVar_Delta', '', False, True)
	plt.show()

	return
def Get_Catalogue(iStart=0,iEnd=-1):
	'''
	'''
	
	if (location__ == "HOME"):
		if (pipeline__=="DR12"):
			path = "/home/helion/Documents/Thèse/Data/Fits/DR12Q_v2_10.fits"
		elif (pipeline__=="MOCK"):
			path = "/home/helion/Documents/Thèse/Data/List/DR11MultipleOfficial.txt"
	elif (location__ == "ICLUST"):
		if (pipeline__=="DR12"):
			path = "/home/gpfs/manip/mnt/bao/hdumasde/Lists/DR12Q_v2_10.fits"
		elif (pipeline__=="MOCK"):
			path = "/home/gpfs/manip/mnt/bao/hdumasde/CrossCorrelation_StartingAgainFrom1347/CrossCorrelation/List/DR11MultipleOfficial.txt"
	print path		
			
	if (pipeline__=="DR12"):
		file_cat_allForest = pyfits.open(path, memmap=True )
		cat_allForest = file_cat_allForest[1].data
		print "  The size of the catalogue is           : " + str(len(cat_allForest))
		cat_allForest = cat_allForest[ cat_allForest["Z_VI"]>minRedshift__]
		print "  We keep Z_VI > " + str(minRedshift__) + "  , the size is      : " + str(len(cat_allForest))
		cat_allForest = cat_allForest[ cat_allForest["Z_VI"]<=maxRedshift__]
		print "  We keep Z_VI <= " + str(maxRedshift__) + "  , the size is      : " + str(len(cat_allForest))
		cat_allForest = cat_allForest[ cat_allForest["BAL_FLAG_VI"]==0]
		print "  We keep BAL_FLAG_VI == 0 , the size is : " + str(len(cat_allForest))
		if (location__=='HOME'):
			cat_allForest = cat_allForest[ (cat_allForest['EBOSS_TARGET0'] & 2**12) > 0  ]
			print "  We keep sequels, the size is : " + str(len(cat_allForest))	
		
		data = [cat_allForest['PLATE'], cat_allForest['MJD'], cat_allForest['FIBERID'], cat_allForest['RA'], cat_allForest['DEC'], cat_allForest['Z_VI']]
		
		del cat_allForest
		del file_cat_allForest
		
	elif (pipeline__=="MOCK"):
		
		tmp_data = numpy.loadtxt(path)
		plate = tmp_data[:,0].astype('int')
		mjd   = tmp_data[:,1].astype('int')
		fiber = tmp_data[:,2].astype('int')
		ra    = tmp_data[:,3]
		dec   = tmp_data[:,4]
		z     = tmp_data[:,5]

		print '  ', len(plate)
		
		tmp_bool = (z>minRedshift__)
		plate = plate[tmp_bool]
		mjd   = mjd[tmp_bool]
		fiber = fiber[tmp_bool]
		ra    = ra[tmp_bool]
		dec   = dec[tmp_bool]
		z     = z[tmp_bool]

		print '  ', len(plate)		
		
		data = [plate, mjd, fiber, ra, dec, z]
		
	return data, iStart, iEnd
def Convert_Fits_To_Ntuples():
	'''

	Convert my fits file to root files

	'''
	

	path     = Get_Data_Fits_File()[1]
	file_cat = pyfits.open(path)
	cat      = file_cat[1].data[:1000]
	
	rootFile = ROOT.TFile("Results0_6999_Mock__DR11.root", "recreate") 
	tree = ROOT.TTree("SDSSQSO", "SDSS QSO")


	### Attributes of forest	
	plate     = array.array("i", [0])
	mjd       = array.array("i", [0])
	fiber     = array.array("i", [0])
	ra_J2000  = array.array("d", [0])
	dec_J2000 = array.array("d", [0])
	RedShift  = array.array("d", [0])
	NbPixel   = array.array("i", [0])

	### Array of forest
	LambdaAbs         = array.array("f", [0.]*nbBinRFMax__)
	DeltaFluxMeth2    = array.array("f", [0.]*nbBinRFMax__)
	DeltaFluxErrMeth2 = array.array("f", [0.]*nbBinRFMax__)
	zAbs              = array.array("f", [0.]*nbBinRFMax__)
	DLACorr           = array.array("f", [1.]*nbBinRFMax__)

	#print LambdaAbs

	tree.Branch("plate",     plate,     "plate/I")
	tree.Branch("mjd",       mjd,       "mjd/I")
	tree.Branch("fiber",     fiber,     "fiber/I")
	tree.Branch("ra_J2000",  ra_J2000,  "ra_J2000/D")
	tree.Branch("dec_J2000", dec_J2000, "dec_J2000/D")
	tree.Branch("RedShift",     RedShift,     "RedShift/D")
	tree.Branch("NbPixel",   NbPixel,   "NbPixel/I")

	tree.Branch("LambdaAbs",          LambdaAbs,         'LambdaAbs['+str(nbBinRFMax__)+']/F')
	tree.Branch("DeltaFluxMeth2",     DeltaFluxMeth2,    'DeltaFluxMeth2['+str(nbBinRFMax__)+']/F') 
	tree.Branch("DeltaFluxErrMeth2",  DeltaFluxErrMeth2, 'DeltaFluxErrMeth2['+str(nbBinRFMax__)+']/F');
	tree.Branch("zAbs",               zAbs,              'zAbs['+str(nbBinRFMax__)+']/F'); 
	tree.Branch("DLACorr",            DLACorr   ,        'DLACorr['+str(nbBinRFMax__)+']/F'); 

	for el in cat:

		plate[0]     = el['PLATE']
		mjd[0]       = el['MJD']
		fiber[0]     = el['FIBERID']
		ra_J2000[0]  = el['RA']
		dec_J2000[0] = el['DEC']
		RedShift[0]  = el['Z_VI']
		NbPixel[0]   = el['NB_PIXEL']

		for i in range(0,nbBinRFMax__):
			LambdaAbs[i]      = el['LAMBDA_OBS'][i]
			DeltaFluxMeth2[i] = el['DELTA'][i]
			zAbs[i]           = el['LAMBDA_OBS'][i]/lambdaRFLya__ -1.
			try:
				DeltaFluxErrMeth2[i] = numpy.power(el['DELTA_IVAR'][i],-0.5)
			except:
				DeltaFluxErrMeth2[i] = 0.

		tree.Fill() 

	rootFile.Write() 
	rootFile.Close()

	return

	
########################################################################
###  Usefull functions
########################################################################
	
	
	
def Get_TProfile(ar1, ar2, nbBin1, withWeight=False, we2=[]):
	'''
	'''
	
	### Get the arrays with histos
	axis   = numpy.histogram2d(ar1, ar2, (nbBin1,1))
	number = axis[0][:,0]
	axis   = axis[1]
	
	### find the half bin size
	half_bin_size = numpy.mean([ axis[i+1]-axis[i] for i in range(0,len(axis)-1) ])/2.
	
	### Get only not empty bins
	bool_number = (number>1)
	
	axis   = axis[ bool_number ]+half_bin_size
	number = number[ bool_number ]
	
	if (withWeight):
		axis2 = numpy.histogram2d(ar1, ar2, (nbBin1,1), weights=we2)[0][:,0]
		mean  = numpy.histogram2d(ar1, ar2, (nbBin1,1), weights=ar2*we2)[0][:,0]
		mean2 = numpy.histogram2d(ar1, ar2, (nbBin1,1), weights=ar2*ar2*we2)[0][:,0]
		
		axis2  = axis2[ bool_number ]
		mean   = mean[ bool_number ]
		mean2  = mean2[ bool_number ]
		
		mean  = mean/axis2
		mean2 = mean2/axis2
	else:
		mean  = numpy.histogram2d(ar1, ar2, (nbBin1,1), weights=ar2)[0][:,0]
		mean2 = numpy.histogram2d(ar1, ar2, (nbBin1,1), weights=ar2*ar2)[0][:,0]
		
		mean   = mean[ bool_number ]
		mean2  = mean2[ bool_number ]
		
		mean  = mean/number
		mean2 = mean2/number
	
	### Get the variance
	mean2 = numpy.sqrt((mean2-mean*mean)/number)
	
	return axis, mean, mean2, number
def deal_with_plot(xaxis, yaxis, title, logx=False, logy=False):
	
	plt.ticklabel_format(style='sci', axis='z', scilimits=(0,0))
	plt.tick_params(axis='both', which='major', labelsize=30)
	
	if (logx):
		plt.xscale('log')
	if (logy):
		plt.yscale('log')
	
	plt.grid(True, which='both')
	plt.title(title, fontsize=40)
	plt.xlabel(xaxis, fontsize=40)
	plt.ylabel(yaxis, fontsize=40)
	plt.legend(fontsize=30, frameon=False, numpoints=1)



########################################################################
###  To get path
########################################################################
	
	
def Get_Path_To_Fits():
	'''
	Return the path to the catalogue
	'''

	if (pipeline__=="DR12"):
		if (location__ == "HOME"):
			path = "/home/helion/Documents/Thèse/Data/Fits/Spectra/spec-"
		elif (location__ == "ICLUST"):
			path = "/home/gpfs/manip/mnt0607/bao/Spectra/SpectraV5_7_0Bailey/"
	elif (pipeline__=="MOCK"):
		if (location__ == "ICLUST"):
			path = "/home/gpfs/manip/mnt0607/bao/MockV4/M3_0_" + str(chunckNb__) + '/' + str(simulNb__).zfill(3) + '/'
	
	print '  Path to specFiles = ', path	
	return path			
def Get_Path_To_Save_New_Fits(iStart=0,iEnd=-1):
	'''
	Return the path to the catalogue
	'''
	
	if (iEnd==-1):
		endString = '.fits'
	else:
		endString = '_'+str(iStart)+'_'+str(iEnd)+'.fits'

	if (pipeline__=="DR12"):
		if (location__ == "HOME"):
			path = "/home/helion/Documents/Thèse/Results/RootFile/allDR12_test" + endString
		elif (location__ == "ICLUST"):
			path = "/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/allDR12_test" + endString
	elif (pipeline__=="MOCK"):
		if (location__ == "ICLUST"):
			path = "/home/gpfs/manip/mnt/bao/MockV4_Production_withOwnTemplate/M3_0_" + str(chunckNb__) + '_python/' + str(simulNb__).zfill(3) +'/Mock__DR11' + endString
		
	print '  Path where to save production fits file = ', path
	return path
def Get_Data_Fits_File():
	'''
	Return the folder and the path to the catalogue
	'''
	
	if (pipeline__=="DR12"):
		if (location__ == "HOME"):
			folder = '/home/helion/Documents/Thèse/Results/RootFile/'
			path   = folder + 'allDR12_test'
		elif (location__ == "ICLUST"):
			folder = '/home/gpfs/manip/mnt/bao/hdumasde/Results/RootFile/FitsFile_DR12/'
			path   = folder + 'allDR12_test10000.fits'
	elif (pipeline__=="MOCK"):
		if (location__ == "ICLUST"):
			folder = '/home/gpfs/manip/mnt/bao/MockV4_Production_withOwnTemplate/M3_0_' + str(chunckNb__) + '_python/' + str(simulNb__).zfill(3) + '/'
			path   = folder + 'allMock.fits'
		
	print '  Path where to get data fits folder = ', folder
	print '  Path where to get data fits file   = ', path
	return [folder,path]


if (len(sys.argv)>=5):

	iStart     = int(sys.argv[1])
	iEnd       = int(sys.argv[2])
	chunckNb__ = int(sys.argv[3])
	simulNb__  = int(sys.argv[4])
	
	#make_all_Fits(iStart,iEnd)
	#Merge_Files()
	Get_Template()
	#Plot_Results()
	#Convert_Fits_To_Ntuples()



'''
if (loopIdx>0 and loopIdx<=nbLoopFirstSteps):


### If delta vs. lambda_RF flat
tmp_interp      = numpy.interp(ar_lambdaRF, templateCorrected[loopIdx-1][0], templateCorrected[loopIdx-1][1])

### If delta vs. lambda_Obs flat
tmp_interp             = numpy.interp(ar_lambdaRF, template[loopIdx-1][0], template[loopIdx-1][1])
tmp_interp             = numpy.multiply(tmp_interp,numpy.interp(ar_lambdaObs, meanTrandObs[loopIdx-1][0], meanTrandObs[loopIdx-1][1]))

### If (delta vs. lambda_RF) and (delta vs. lambda_Obs) flat
tmp_interp      = numpy.interp(ar_lambdaRF, templateCorrected[loopIdx-1][0], templateCorrected[loopIdx-1][1])*numpy.interp(ar_lambdaObs, meanTrandObs[loopIdx-1][0], meanTrandObs[loopIdx-1][1])

ar_delta        = ar_flux/tmp_interp-1.
log_delta_ivar  = numpy.log10(cat['NORM_FLUX_IVAR'][ar_cut]*tmp_interp*tmp_interp)
ar_weight       = 1./(sigma2LSS[loopIdx-1]+1./(cat['NORM_FLUX_IVAR'][ar_cut]*tmp_interp*tmp_interp*eta[loopIdx-1]))
else:
'''










		
		
